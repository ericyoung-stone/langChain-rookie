{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to use chat models to call tools\n",
    "参考: [How to use chat models to call tools](https://python.langchain.com/docs/how_to/tool_calling/)\n",
    "- Chat models\n",
    "- Tool calling\n",
    "- Tools\n",
    "- Output parsers\n",
    "- 请记住，“工具调用”这个名字让人以为模型会直接执行某些操作，但实际上并非如此！\n",
    "- **模型只会生成工具的参数，而运行工具（或不运行）则由用户决定。**\n",
    "- 工具调用是一种**生成模型结构化输出**的一般技术，即使你无意调用任何工具，你也可以使用它。例如，**从非结构化文本中提取信息**就是一种使用场景。\n",
    "    - 工具调用不是所有的模型都支持的,支持tool的模型会更方便调用tool,见: [LLM providers](https://python.langchain.com/docs/integrations/chat/)\n",
    "    - 不支持tool的模型可以通过ChatOpenAI类设置base_url,返回的llm 支持结构化输出和bind_tools\n"
   ],
   "id": "e7918bfcf96be661"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## chat models",
   "id": "e9c63d079d309dfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:49.523626Z",
     "start_time": "2025-03-16T04:09:49.506602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ericyoung/ysx/code/github-study/langChain-rookie')\n",
    "from env_utils import load_environment_variables\n",
    "\n",
    "load_environment_variables()"
   ],
   "id": "e04acf8b6249bb5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__file__: /Users/ericyoung/ysx/code/github-study/langChain-rookie/env_utils.py\n",
      "dotenv_path1: /Users/ericyoung/ysx/code/github-study/langChain-rookie/.env\n",
      "load env ok\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 支持tool的 chat model",
   "id": "4d69472a833612b7"
  },
  {
   "cell_type": "code",
   "id": "5388aa50-da7b-47af-9141-a295fafe1975",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:50.059055Z",
     "start_time": "2025-03-16T04:09:49.595312Z"
    }
   },
   "source": [
    "# Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "# llm = ChatOllama(\n",
    "#     model=\"qwen2.5:latest\", # gemma3:latest(不支持tool)\n",
    "#     temperature=0.7,\n",
    "#     # other params...\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 不支持tool的chat model",
   "id": "8bcc565d1b43f814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:54.852949Z",
     "start_time": "2025-03-16T04:09:50.143684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 任何chat model\n",
    "from models import MyOpenAIModel\n",
    "\n",
    "model = MyOpenAIModel()\n",
    "response = model.generate(\"你好，介绍一下你自己\")\n",
    "print(response)"
   ],
   "id": "31ac354122cdeffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是Gemma，一个由 Google DeepMind 训练的大型语言模型。我是一个开放权重的模型，这意味着我的权重是公开的，您可以自由地使用和修改我。\n",
      "\n",
      "我可以理解和生成文本，可以帮助您进行各种任务，例如：\n",
      "\n",
      "*   回答问题\n",
      "*   创作不同类型的文本格式（诗歌、代码、剧本、音乐作品、电子邮件、信件等）\n",
      "*   翻译语言\n",
      "*   总结文本\n",
      "\n",
      "我是由 Gemma 团队构建的，并且一直在不断学习和改进。\n",
      "\n",
      "您想和我聊些什么呢？ 😊您好！我是Gemma，一个由 Google DeepMind 训练的大型语言模型。我是一个开放权重的模型，这意味着我的权重是公开的，您可以自由地使用和修改我。\n",
      "\n",
      "我可以理解和生成文本，可以帮助您进行各种任务，例如：\n",
      "\n",
      "*   回答问题\n",
      "*   创作不同类型的文本格式（诗歌、代码、剧本、音乐作品、电子邮件、信件等）\n",
      "*   翻译语言\n",
      "*   总结文本\n",
      "\n",
      "我是由 Gemma 团队构建的，并且一直在不断学习和改进。\n",
      "\n",
      "您想和我聊些什么呢？ 😊\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ⭐️ 不支持tool模型 利用 ChatOpenAI (使用base_url) 实现 bind_tools\n",
    "- 支持结构化输出, with_structured_output方法\n",
    "- 支持使用工具, bind_tools方法\n",
    "- llm = ChatOpenAI(\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # api_key=\"...\",\n",
    "                # base_url=\"...\",\n",
    "                # organization=\"...\",\n",
    "                # other params...\n",
    "            )"
   ],
   "id": "c5f1c53aef76d8bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.334130Z",
     "start_time": "2025-03-16T04:09:54.890427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models import get_base_url_model_with_tools\n",
    "llm = get_base_url_model_with_tools()\n",
    "print(llm.invoke(\"你是谁?\").content)"
   ],
   "id": "4b823fdd30da3025",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是Gemma，一个由 Google DeepMind 训练的大型语言模型。我是一个开放权重的模型，可以广泛地被公众使用。\n",
      "\n",
      "你可以把我当作一个文本生成工具来理解。我可以根据你给我的提示生成文本、翻译语言、回答问题等等。\n",
      "\n",
      "请注意，我没有连接到互联网，也无法访问实时信息。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?定义工具\n",
    "Defining tool schemas  定义工具模式\n",
    "- 为了使模型能够调用工具，我们需要传递描述工具功能及其参数的工具模式。\n",
    "- 支持工具调用功能的聊天模型实现了一个**.bind_tools() 方法**，用于向模型传递工具模式。\n",
    "- 定义工具模式的方式主要有:\n",
    "    - Python 函数（带有类型提示和文档字符串）\n",
    "    - Pydantic 模型、\n",
    "    - TypedDict 类或\n",
    "    - LangChain Tool 对象传递。--- 通过@tool装饰器实现,详见: [How to create tools](https://python.langchain.com/docs/how_to/custom_tools/#creating-tools-from-functions)\n",
    "- 模型后续的调用将与提示一起传递这些工具模式。"
   ],
   "id": "584541e40f0d878"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Python 函数",
   "id": "a482d3366e4ac52b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.354934Z",
     "start_time": "2025-03-16T04:09:57.352219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The function name, type hints, and docstring are all part of the tool\n",
    "# schema that's passed to the model. Defining good, descriptive schemas\n",
    "# is an extension of prompt engineering and is an important part of\n",
    "# getting models to perform well.\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b"
   ],
   "id": "c8acff3c9a70fd16",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ?LangChain 工具\n",
    "-  通过@tool装饰器实现,详见: [How to create tools](https://python.langchain.com/docs/how_to/custom_tools/#creating-tools-from-functions)"
   ],
   "id": "fb3a6018f9dfe79a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pydantic 类\n",
    "- 使用 Pydantic 定义不带伴随函数的模式\n",
    "    - 除非提供默认值，否则所有字段都是 required"
   ],
   "id": "9254e5430f2b27b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.371548Z",
     "start_time": "2025-03-16T04:09:57.367924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ],
   "id": "e4f22a73647b6513",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### TypedDict类-带类型提示\n",
    "- 需要 langchain-core>=0.2.25\n",
    "- 可使用 TypedDicts 和注解"
   ],
   "id": "23fc7127a464d0ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.384911Z",
     "start_time": "2025-03-16T04:09:57.382247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class add(TypedDict):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    # Annotations must have the type and can optionally include a default value and description (in that order).\n",
    "    a: Annotated[int, ..., \"First integer\"]\n",
    "    b: Annotated[int, ..., \"Second integer\"]\n",
    "\n",
    "\n",
    "class multiply(TypedDict):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: Annotated[int, ..., \"First integer\"]\n",
    "    b: Annotated[int, ..., \"Second integer\"]\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ],
   "id": "b02115597017d5c7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## bind_tools\n",
    "- 将这些模式绑定到聊天模型，我们将使用 .bind_tools() 方法。\n",
    "- 此方法处理将 add 和 multiply 模式转换为模型所需的正确格式。\n",
    "- 每次调用模型时，工具模式将被传递给它。\n",
    "- 可以看到响应中的tool_calls中使用了multiply工具方法,工具调用成功"
   ],
   "id": "f78bcfd19bd912fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:59.928829Z",
     "start_time": "2025-03-16T04:09:57.395489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ],
   "id": "945ede7bb826861b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '576632143', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 563, 'total_tokens': 600, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-3-4b-it', 'system_fingerprint': 'gemma-3-4b-it', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0075b18f-9a68-4116-ac31-6893053f8b09-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '576632143', 'type': 'tool_call'}], usage_metadata={'input_tokens': 563, 'output_tokens': 37, 'total_tokens': 600, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 工具调用 Tool calls\n",
    "- LLM响应中 .tool_calls 属性就是工具调用 ToolCall对象 列表, 请注意聊天模型可以一次调用多个工具。\n",
    "- ToolCall 是一个带类型的字典，包含工具名称name、参数值字典args以及（可选地）一个标识符id。没有工具调用的消息默认将此属性设置为空列表。\n",
    "- .tool_calls 属性应包含有效的工具调用。\n",
    "    - 请注意，有时模型提供者可能会输出格式错误的工具调用（例如，无效的 JSON 参数）。\n",
    "    - 在这种情况下，当解析失败时， .invalid_tool_calls 属性中会填充 InvalidToolCall 实例。\n",
    "    - InvalidToolCall 可以具有名称、字符串参数、标识符和错误消息。"
   ],
   "id": "c54917f0ce908666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:10:02.235853Z",
     "start_time": "2025-03-16T04:09:59.952013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ],
   "id": "83492d4fb944d6da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': '541637767',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': '646266744',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:10:04.662615Z",
     "start_time": "2025-03-16T04:10:02.255380Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools.invoke(query)",
   "id": "459604a051bae697",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '416249349', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': '802804964', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 575, 'total_tokens': 649, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-3-4b-it', 'system_fingerprint': 'gemma-3-4b-it', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-762062ec-3caa-4a38-924a-d23cfbc9c6b6-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '416249349', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '802804964', 'type': 'tool_call'}], usage_metadata={'input_tokens': 575, 'output_tokens': 74, 'total_tokens': 649, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parsing  解析\n",
    "- 如果需要，可以进一步处理输出。例如，我们可以使用 PydanticToolsParser 将 .tool_calls 上已填充的现有值转换为 Pydantic 对象："
   ],
   "id": "a17068c97e88b484"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:10:07.202623Z",
     "start_time": "2025-03-16T04:10:04.706986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[add, multiply])\n",
    "chain.invoke(query)"
   ],
   "id": "5338405511214ed8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[multiply(a=3, b=12), add(a=11, b=49)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?如何将工具输出传递给聊天模型\n",
    "[How to pass tool outputs to chat models](https://python.langchain.com/docs/how_to/tool_results_pass_to_model/)"
   ],
   "id": "4a04882aad9b7c3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:18:59.666910Z",
     "start_time": "2025-03-16T04:18:59.648264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "id": "307659a86e1b0574",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 让模型调用一个工具。我们将把它添加到一个消息列表中，我们将把这些消息视为对话历史：",
   "id": "6f7786165f3b63fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:19:03.526616Z",
     "start_time": "2025-03-16T04:19:00.511567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ],
   "id": "8e4bd0af9f30e272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '783362832', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '863709297', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 如果我们调用一个 LangChain Tool 并传入一个 ToolCall ，我们将会自动获得一个 ToolMessage 可以反馈给模型\n",
    "\n",
    "- 该功能在 langchain-core == 0.2.19 中添加。请确保您的包是最新的。\n",
    "- 如果您使用的是 langchain-core 的较早版本，请需要从工具中提取 args 字段并手动构建一个 ToolMessage"
   ],
   "id": "273ed8bf22a522bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ],
   "id": "7e7ca61d905c2b63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 最后，我们将使用工具结果调用模型。模型将利用这些信息生成对我们原始查询的最终答案：",
   "id": "70ad3ef5b5834c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:22:48.650627Z",
     "start_time": "2025-03-16T04:22:47.657175Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools.invoke(messages)",
   "id": "33ae5d691ac7762b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 670, 'total_tokens': 670, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-3-4b-it', 'system_fingerprint': 'gemma-3-4b-it', 'finish_reason': 'stop', 'logprobs': None}, id='run-1683833f-8551-4bcc-ad3d-c2d10d19fb1a-0', usage_metadata={'input_tokens': 670, 'output_tokens': 0, 'total_tokens': 670, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?如何将运行时值传递给工具\n",
    "[How to pass run time values to tools](https://python.langchain.com/docs/how_to/tool_runtime/)"
   ],
   "id": "9ecb94c12d41a100"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14892d9c51bad786"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
