{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to use chat models to call tools\n",
    "å‚è€ƒ: [How to use chat models to call tools](https://python.langchain.com/docs/how_to/tool_calling/)\n",
    "- Chat models\n",
    "- Tool calling\n",
    "- Tools\n",
    "- Output parsers\n",
    "- è¯·è®°ä½ï¼Œâ€œå·¥å…·è°ƒç”¨â€è¿™ä¸ªåå­—è®©äººä»¥ä¸ºæ¨¡å‹ä¼šç›´æ¥æ‰§è¡ŒæŸäº›æ“ä½œï¼Œä½†å®é™…ä¸Šå¹¶éå¦‚æ­¤ï¼\n",
    "- **æ¨¡å‹åªä¼šç”Ÿæˆå·¥å…·çš„å‚æ•°ï¼Œè€Œè¿è¡Œå·¥å…·ï¼ˆæˆ–ä¸è¿è¡Œï¼‰åˆ™ç”±ç”¨æˆ·å†³å®šã€‚**\n",
    "- å·¥å…·è°ƒç”¨æ˜¯ä¸€ç§**ç”Ÿæˆæ¨¡å‹ç»“æ„åŒ–è¾“å‡º**çš„ä¸€èˆ¬æŠ€æœ¯ï¼Œå³ä½¿ä½ æ— æ„è°ƒç”¨ä»»ä½•å·¥å…·ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨å®ƒã€‚ä¾‹å¦‚ï¼Œ**ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ä¿¡æ¯**å°±æ˜¯ä¸€ç§ä½¿ç”¨åœºæ™¯ã€‚\n",
    "    - å·¥å…·è°ƒç”¨ä¸æ˜¯æ‰€æœ‰çš„æ¨¡å‹éƒ½æ”¯æŒçš„,æ”¯æŒtoolçš„æ¨¡å‹ä¼šæ›´æ–¹ä¾¿è°ƒç”¨tool,è§: [LLM providers](https://python.langchain.com/docs/integrations/chat/)\n",
    "    - ä¸æ”¯æŒtoolçš„æ¨¡å‹å¯ä»¥é€šè¿‡ChatOpenAIç±»è®¾ç½®base_url,è¿”å›çš„llm æ”¯æŒç»“æ„åŒ–è¾“å‡ºå’Œbind_tools\n"
   ],
   "id": "e7918bfcf96be661"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## chat models",
   "id": "e9c63d079d309dfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:49.523626Z",
     "start_time": "2025-03-16T04:09:49.506602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ericyoung/ysx/code/github-study/langChain-rookie')\n",
    "from env_utils import load_environment_variables\n",
    "\n",
    "load_environment_variables()"
   ],
   "id": "e04acf8b6249bb5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__file__: /Users/ericyoung/ysx/code/github-study/langChain-rookie/env_utils.py\n",
      "dotenv_path1: /Users/ericyoung/ysx/code/github-study/langChain-rookie/.env\n",
      "load env ok\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### æ”¯æŒtoolçš„ chat model",
   "id": "4d69472a833612b7"
  },
  {
   "cell_type": "code",
   "id": "5388aa50-da7b-47af-9141-a295fafe1975",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:50.059055Z",
     "start_time": "2025-03-16T04:09:49.595312Z"
    }
   },
   "source": [
    "# Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "# llm = ChatOllama(\n",
    "#     model=\"qwen2.5:latest\", # gemma3:latest(ä¸æ”¯æŒtool)\n",
    "#     temperature=0.7,\n",
    "#     # other params...\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ä¸æ”¯æŒtoolçš„chat model",
   "id": "8bcc565d1b43f814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:54.852949Z",
     "start_time": "2025-03-16T04:09:50.143684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»»ä½•chat model\n",
    "from models import MyOpenAIModel\n",
    "\n",
    "model = MyOpenAIModel()\n",
    "response = model.generate(\"ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\")\n",
    "print(response)"
   ],
   "id": "31ac354122cdeffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨å¥½ï¼æˆ‘æ˜¯Gemmaï¼Œä¸€ä¸ªç”± Google DeepMind è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘æ˜¯ä¸€ä¸ªå¼€æ”¾æƒé‡çš„æ¨¡å‹ï¼Œè¿™æ„å‘³ç€æˆ‘çš„æƒé‡æ˜¯å…¬å¼€çš„ï¼Œæ‚¨å¯ä»¥è‡ªç”±åœ°ä½¿ç”¨å’Œä¿®æ”¹æˆ‘ã€‚\n",
      "\n",
      "æˆ‘å¯ä»¥ç†è§£å’Œç”Ÿæˆæ–‡æœ¬ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š\n",
      "\n",
      "*   å›ç­”é—®é¢˜\n",
      "*   åˆ›ä½œä¸åŒç±»å‹çš„æ–‡æœ¬æ ¼å¼ï¼ˆè¯—æ­Œã€ä»£ç ã€å‰§æœ¬ã€éŸ³ä¹ä½œå“ã€ç”µå­é‚®ä»¶ã€ä¿¡ä»¶ç­‰ï¼‰\n",
      "*   ç¿»è¯‘è¯­è¨€\n",
      "*   æ€»ç»“æ–‡æœ¬\n",
      "\n",
      "æˆ‘æ˜¯ç”± Gemma å›¢é˜Ÿæ„å»ºçš„ï¼Œå¹¶ä¸”ä¸€ç›´åœ¨ä¸æ–­å­¦ä¹ å’Œæ”¹è¿›ã€‚\n",
      "\n",
      "æ‚¨æƒ³å’Œæˆ‘èŠäº›ä»€ä¹ˆå‘¢ï¼Ÿ ğŸ˜Šæ‚¨å¥½ï¼æˆ‘æ˜¯Gemmaï¼Œä¸€ä¸ªç”± Google DeepMind è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘æ˜¯ä¸€ä¸ªå¼€æ”¾æƒé‡çš„æ¨¡å‹ï¼Œè¿™æ„å‘³ç€æˆ‘çš„æƒé‡æ˜¯å…¬å¼€çš„ï¼Œæ‚¨å¯ä»¥è‡ªç”±åœ°ä½¿ç”¨å’Œä¿®æ”¹æˆ‘ã€‚\n",
      "\n",
      "æˆ‘å¯ä»¥ç†è§£å’Œç”Ÿæˆæ–‡æœ¬ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š\n",
      "\n",
      "*   å›ç­”é—®é¢˜\n",
      "*   åˆ›ä½œä¸åŒç±»å‹çš„æ–‡æœ¬æ ¼å¼ï¼ˆè¯—æ­Œã€ä»£ç ã€å‰§æœ¬ã€éŸ³ä¹ä½œå“ã€ç”µå­é‚®ä»¶ã€ä¿¡ä»¶ç­‰ï¼‰\n",
      "*   ç¿»è¯‘è¯­è¨€\n",
      "*   æ€»ç»“æ–‡æœ¬\n",
      "\n",
      "æˆ‘æ˜¯ç”± Gemma å›¢é˜Ÿæ„å»ºçš„ï¼Œå¹¶ä¸”ä¸€ç›´åœ¨ä¸æ–­å­¦ä¹ å’Œæ”¹è¿›ã€‚\n",
      "\n",
      "æ‚¨æƒ³å’Œæˆ‘èŠäº›ä»€ä¹ˆå‘¢ï¼Ÿ ğŸ˜Š\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### â­ï¸ ä¸æ”¯æŒtoolæ¨¡å‹ åˆ©ç”¨ ChatOpenAI (ä½¿ç”¨base_url) å®ç° bind_tools\n",
    "- æ”¯æŒç»“æ„åŒ–è¾“å‡º, with_structured_outputæ–¹æ³•\n",
    "- æ”¯æŒä½¿ç”¨å·¥å…·, bind_toolsæ–¹æ³•\n",
    "- llm = ChatOpenAI(\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0,\n",
    "                max_tokens=None,\n",
    "                timeout=None,\n",
    "                max_retries=2,\n",
    "                # api_key=\"...\",\n",
    "                # base_url=\"...\",\n",
    "                # organization=\"...\",\n",
    "                # other params...\n",
    "            )"
   ],
   "id": "c5f1c53aef76d8bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.334130Z",
     "start_time": "2025-03-16T04:09:54.890427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models import get_base_url_model_with_tools\n",
    "llm = get_base_url_model_with_tools()\n",
    "print(llm.invoke(\"ä½ æ˜¯è°?\").content)"
   ],
   "id": "4b823fdd30da3025",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯Gemmaï¼Œä¸€ä¸ªç”± Google DeepMind è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘æ˜¯ä¸€ä¸ªå¼€æ”¾æƒé‡çš„æ¨¡å‹ï¼Œå¯ä»¥å¹¿æ³›åœ°è¢«å…¬ä¼—ä½¿ç”¨ã€‚\n",
      "\n",
      "ä½ å¯ä»¥æŠŠæˆ‘å½“ä½œä¸€ä¸ªæ–‡æœ¬ç”Ÿæˆå·¥å…·æ¥ç†è§£ã€‚æˆ‘å¯ä»¥æ ¹æ®ä½ ç»™æˆ‘çš„æç¤ºç”Ÿæˆæ–‡æœ¬ã€ç¿»è¯‘è¯­è¨€ã€å›ç­”é—®é¢˜ç­‰ç­‰ã€‚\n",
      "\n",
      "è¯·æ³¨æ„ï¼Œæˆ‘æ²¡æœ‰è¿æ¥åˆ°äº’è”ç½‘ï¼Œä¹Ÿæ— æ³•è®¿é—®å®æ—¶ä¿¡æ¯ã€‚\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?å®šä¹‰å·¥å…·\n",
    "Defining tool schemas  å®šä¹‰å·¥å…·æ¨¡å¼\n",
    "- ä¸ºäº†ä½¿æ¨¡å‹èƒ½å¤Ÿè°ƒç”¨å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’æè¿°å·¥å…·åŠŸèƒ½åŠå…¶å‚æ•°çš„å·¥å…·æ¨¡å¼ã€‚\n",
    "- æ”¯æŒå·¥å…·è°ƒç”¨åŠŸèƒ½çš„èŠå¤©æ¨¡å‹å®ç°äº†ä¸€ä¸ª**.bind_tools() æ–¹æ³•**ï¼Œç”¨äºå‘æ¨¡å‹ä¼ é€’å·¥å…·æ¨¡å¼ã€‚\n",
    "- å®šä¹‰å·¥å…·æ¨¡å¼çš„æ–¹å¼ä¸»è¦æœ‰:\n",
    "    - Python å‡½æ•°ï¼ˆå¸¦æœ‰ç±»å‹æç¤ºå’Œæ–‡æ¡£å­—ç¬¦ä¸²ï¼‰\n",
    "    - Pydantic æ¨¡å‹ã€\n",
    "    - TypedDict ç±»æˆ–\n",
    "    - LangChain Tool å¯¹è±¡ä¼ é€’ã€‚--- é€šè¿‡@toolè£…é¥°å™¨å®ç°,è¯¦è§: [How to create tools](https://python.langchain.com/docs/how_to/custom_tools/#creating-tools-from-functions)\n",
    "- æ¨¡å‹åç»­çš„è°ƒç”¨å°†ä¸æç¤ºä¸€èµ·ä¼ é€’è¿™äº›å·¥å…·æ¨¡å¼ã€‚"
   ],
   "id": "584541e40f0d878"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Python å‡½æ•°",
   "id": "a482d3366e4ac52b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.354934Z",
     "start_time": "2025-03-16T04:09:57.352219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The function name, type hints, and docstring are all part of the tool\n",
    "# schema that's passed to the model. Defining good, descriptive schemas\n",
    "# is an extension of prompt engineering and is an important part of\n",
    "# getting models to perform well.\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b"
   ],
   "id": "c8acff3c9a70fd16",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ?LangChain å·¥å…·\n",
    "-  é€šè¿‡@toolè£…é¥°å™¨å®ç°,è¯¦è§: [How to create tools](https://python.langchain.com/docs/how_to/custom_tools/#creating-tools-from-functions)"
   ],
   "id": "fb3a6018f9dfe79a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pydantic ç±»\n",
    "- ä½¿ç”¨ Pydantic å®šä¹‰ä¸å¸¦ä¼´éšå‡½æ•°çš„æ¨¡å¼\n",
    "    - é™¤éæä¾›é»˜è®¤å€¼ï¼Œå¦åˆ™æ‰€æœ‰å­—æ®µéƒ½æ˜¯ required"
   ],
   "id": "9254e5430f2b27b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.371548Z",
     "start_time": "2025-03-16T04:09:57.367924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")"
   ],
   "id": "e4f22a73647b6513",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### TypedDictç±»-å¸¦ç±»å‹æç¤º\n",
    "- éœ€è¦ langchain-core>=0.2.25\n",
    "- å¯ä½¿ç”¨ TypedDicts å’Œæ³¨è§£"
   ],
   "id": "23fc7127a464d0ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:57.384911Z",
     "start_time": "2025-03-16T04:09:57.382247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class add(TypedDict):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    # Annotations must have the type and can optionally include a default value and description (in that order).\n",
    "    a: Annotated[int, ..., \"First integer\"]\n",
    "    b: Annotated[int, ..., \"Second integer\"]\n",
    "\n",
    "\n",
    "class multiply(TypedDict):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: Annotated[int, ..., \"First integer\"]\n",
    "    b: Annotated[int, ..., \"Second integer\"]\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ],
   "id": "b02115597017d5c7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## bind_tools\n",
    "- å°†è¿™äº›æ¨¡å¼ç»‘å®šåˆ°èŠå¤©æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ .bind_tools() æ–¹æ³•ã€‚\n",
    "- æ­¤æ–¹æ³•å¤„ç†å°† add å’Œ multiply æ¨¡å¼è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„æ­£ç¡®æ ¼å¼ã€‚\n",
    "- æ¯æ¬¡è°ƒç”¨æ¨¡å‹æ—¶ï¼Œå·¥å…·æ¨¡å¼å°†è¢«ä¼ é€’ç»™å®ƒã€‚\n",
    "- å¯ä»¥çœ‹åˆ°å“åº”ä¸­çš„tool_callsä¸­ä½¿ç”¨äº†multiplyå·¥å…·æ–¹æ³•,å·¥å…·è°ƒç”¨æˆåŠŸ"
   ],
   "id": "f78bcfd19bd912fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:09:59.928829Z",
     "start_time": "2025-03-16T04:09:57.395489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ],
   "id": "945ede7bb826861b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '576632143', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 563, 'total_tokens': 600, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-3-4b-it', 'system_fingerprint': 'gemma-3-4b-it', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0075b18f-9a68-4116-ac31-6893053f8b09-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '576632143', 'type': 'tool_call'}], usage_metadata={'input_tokens': 563, 'output_tokens': 37, 'total_tokens': 600, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## å·¥å…·è°ƒç”¨ Tool calls\n",
    "- LLMå“åº”ä¸­ .tool_calls å±æ€§å°±æ˜¯å·¥å…·è°ƒç”¨ ToolCallå¯¹è±¡ åˆ—è¡¨, è¯·æ³¨æ„èŠå¤©æ¨¡å‹å¯ä»¥ä¸€æ¬¡è°ƒç”¨å¤šä¸ªå·¥å…·ã€‚\n",
    "- ToolCall æ˜¯ä¸€ä¸ªå¸¦ç±»å‹çš„å­—å…¸ï¼ŒåŒ…å«å·¥å…·åç§°nameã€å‚æ•°å€¼å­—å…¸argsä»¥åŠï¼ˆå¯é€‰åœ°ï¼‰ä¸€ä¸ªæ ‡è¯†ç¬¦idã€‚æ²¡æœ‰å·¥å…·è°ƒç”¨çš„æ¶ˆæ¯é»˜è®¤å°†æ­¤å±æ€§è®¾ç½®ä¸ºç©ºåˆ—è¡¨ã€‚\n",
    "- .tool_calls å±æ€§åº”åŒ…å«æœ‰æ•ˆçš„å·¥å…·è°ƒç”¨ã€‚\n",
    "    - è¯·æ³¨æ„ï¼Œæœ‰æ—¶æ¨¡å‹æä¾›è€…å¯èƒ½ä¼šè¾“å‡ºæ ¼å¼é”™è¯¯çš„å·¥å…·è°ƒç”¨ï¼ˆä¾‹å¦‚ï¼Œæ— æ•ˆçš„ JSON å‚æ•°ï¼‰ã€‚\n",
    "    - åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå½“è§£æå¤±è´¥æ—¶ï¼Œ .invalid_tool_calls å±æ€§ä¸­ä¼šå¡«å…… InvalidToolCall å®ä¾‹ã€‚\n",
    "    - InvalidToolCall å¯ä»¥å…·æœ‰åç§°ã€å­—ç¬¦ä¸²å‚æ•°ã€æ ‡è¯†ç¬¦å’Œé”™è¯¯æ¶ˆæ¯ã€‚"
   ],
   "id": "c54917f0ce908666"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:10:02.235853Z",
     "start_time": "2025-03-16T04:09:59.952013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ],
   "id": "83492d4fb944d6da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': '541637767',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': '646266744',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:10:04.662615Z",
     "start_time": "2025-03-16T04:10:02.255380Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools.invoke(query)",
   "id": "459604a051bae697",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '416249349', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': '802804964', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 575, 'total_tokens': 649, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-3-4b-it', 'system_fingerprint': 'gemma-3-4b-it', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-762062ec-3caa-4a38-924a-d23cfbc9c6b6-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '416249349', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '802804964', 'type': 'tool_call'}], usage_metadata={'input_tokens': 575, 'output_tokens': 74, 'total_tokens': 649, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parsing  è§£æ\n",
    "- å¦‚æœéœ€è¦ï¼Œå¯ä»¥è¿›ä¸€æ­¥å¤„ç†è¾“å‡ºã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ PydanticToolsParser å°† .tool_calls ä¸Šå·²å¡«å……çš„ç°æœ‰å€¼è½¬æ¢ä¸º Pydantic å¯¹è±¡ï¼š"
   ],
   "id": "a17068c97e88b484"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:10:07.202623Z",
     "start_time": "2025-03-16T04:10:04.706986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[add, multiply])\n",
    "chain.invoke(query)"
   ],
   "id": "5338405511214ed8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[multiply(a=3, b=12), add(a=11, b=49)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?å¦‚ä½•å°†å·¥å…·è¾“å‡ºä¼ é€’ç»™èŠå¤©æ¨¡å‹\n",
    "[How to pass tool outputs to chat models](https://python.langchain.com/docs/how_to/tool_results_pass_to_model/)"
   ],
   "id": "4a04882aad9b7c3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:18:59.666910Z",
     "start_time": "2025-03-16T04:18:59.648264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ],
   "id": "307659a86e1b0574",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### è®©æ¨¡å‹è°ƒç”¨ä¸€ä¸ªå·¥å…·ã€‚æˆ‘ä»¬å°†æŠŠå®ƒæ·»åŠ åˆ°ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠè¿™äº›æ¶ˆæ¯è§†ä¸ºå¯¹è¯å†å²ï¼š",
   "id": "6f7786165f3b63fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:19:03.526616Z",
     "start_time": "2025-03-16T04:19:00.511567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ],
   "id": "8e4bd0af9f30e272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '783362832', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '863709297', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### å¦‚æœæˆ‘ä»¬è°ƒç”¨ä¸€ä¸ª LangChain Tool å¹¶ä¼ å…¥ä¸€ä¸ª ToolCall ï¼Œæˆ‘ä»¬å°†ä¼šè‡ªåŠ¨è·å¾—ä¸€ä¸ª ToolMessage å¯ä»¥åé¦ˆç»™æ¨¡å‹\n",
    "\n",
    "- è¯¥åŠŸèƒ½åœ¨ langchain-core == 0.2.19 ä¸­æ·»åŠ ã€‚è¯·ç¡®ä¿æ‚¨çš„åŒ…æ˜¯æœ€æ–°çš„ã€‚\n",
    "- å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ langchain-core çš„è¾ƒæ—©ç‰ˆæœ¬ï¼Œè¯·éœ€è¦ä»å·¥å…·ä¸­æå– args å­—æ®µå¹¶æ‰‹åŠ¨æ„å»ºä¸€ä¸ª ToolMessage"
   ],
   "id": "273ed8bf22a522bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ],
   "id": "7e7ca61d905c2b63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### æœ€åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å·¥å…·ç»“æœè°ƒç”¨æ¨¡å‹ã€‚æ¨¡å‹å°†åˆ©ç”¨è¿™äº›ä¿¡æ¯ç”Ÿæˆå¯¹æˆ‘ä»¬åŸå§‹æŸ¥è¯¢çš„æœ€ç»ˆç­”æ¡ˆï¼š",
   "id": "70ad3ef5b5834c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:22:48.650627Z",
     "start_time": "2025-03-16T04:22:47.657175Z"
    }
   },
   "cell_type": "code",
   "source": "llm_with_tools.invoke(messages)",
   "id": "33ae5d691ac7762b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 0, 'prompt_tokens': 670, 'total_tokens': 670, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gemma-3-4b-it', 'system_fingerprint': 'gemma-3-4b-it', 'finish_reason': 'stop', 'logprobs': None}, id='run-1683833f-8551-4bcc-ad3d-c2d10d19fb1a-0', usage_metadata={'input_tokens': 670, 'output_tokens': 0, 'total_tokens': 670, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ?å¦‚ä½•å°†è¿è¡Œæ—¶å€¼ä¼ é€’ç»™å·¥å…·\n",
    "[How to pass run time values to tools](https://python.langchain.com/docs/how_to/tool_runtime/)"
   ],
   "id": "9ecb94c12d41a100"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14892d9c51bad786"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
